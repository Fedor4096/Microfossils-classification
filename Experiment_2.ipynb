{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20f68cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "#from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613b18d",
   "metadata": {},
   "source": [
    "## 1. Препроцессинг изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96024a1d",
   "metadata": {},
   "source": [
    "### 1.1 Очистка папок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4940cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_folder(mydir):\n",
    "    filelist = [f for f in os.listdir(mydir)]\n",
    "    for f in filelist:\n",
    "        os.remove(os.path.join(mydir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6955b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir('data/train_a'):\n",
    "    clear_folder(f'data/train_a/{i}')\n",
    "    \n",
    "for i in os.listdir('data/test_a'):\n",
    "    clear_folder(f'data/test_a/{i}')\n",
    "\n",
    "for i in os.listdir('data/train_c'):\n",
    "    clear_folder(f'data/train_c/{i}')\n",
    "    \n",
    "for i in os.listdir('data/test_c'):\n",
    "    clear_folder(f'data/test_c/{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad0fc4",
   "metadata": {},
   "source": [
    "### 1.2 Выбор изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4268f07b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_names_a = list(glob.glob('data/Aldanella_attleborensis/*Plate_?*_?*a.tif'))\n",
    "data_names_c = list(glob.glob('data/Aldanella_attleborensis/*Plate_?_?*c.tif'))\n",
    "f_1 = open('data/Aldanella_attleborensis/different_angle.txt', 'rt')\n",
    "f_2 = open('data/Aldanella_attleborensis/miss_view.txt', 'rt')\n",
    "diff_angle = f_1.readlines()\n",
    "miss_view = f_2.readlines()\n",
    "for i, pic in enumerate(diff_angle):\n",
    "    diff_angle[i] = f'data/Aldanella_attleborensis\\\\{pic.rstrip()}.tif'#обрезаем символы на конце строки '\\n'\n",
    "for i, pic in enumerate(miss_view):\n",
    "    miss_view[i] = f'data/Aldanella_attleborensis\\\\{pic.rstrip()}.tif'\n",
    "\n",
    "for pic in diff_angle:\n",
    "    if pic in data_names_a:\n",
    "        data_names_a.remove(pic)\n",
    "        if pic[:-5]+'c.tif' in data_names_c:\n",
    "            data_names_c.remove(pic[:-5]+'c.tif')\n",
    "for pic in diff_angle:\n",
    "    if pic in data_names_c:\n",
    "        data_names_c.remove(pic)\n",
    "\n",
    "for pic in miss_view:\n",
    "    if (pic[-5:-4] == 'c')==True and (pic[:-5]+'a.tif' in diff_angle)==False and (pic[:-5]+'a.tif' in miss_view)==False:\n",
    "        data_names_a.remove(pic[:-5]+'a.tif')\n",
    "    if pic[-5:-4] == 'a' and (pic[:-5]+'c.tif' in diff_angle)==False and (pic[:-5]+'c.tif' in miss_view)==False:\n",
    "        data_names_c.remove(pic[:-5]+'c.tif')\n",
    "#print(len(data_names_a))\n",
    "#print(data_names_a)\n",
    "#print(len(data_names_c))\n",
    "#print(data_names_c)\n",
    "\n",
    "f_1.close()\n",
    "f_2.close()\n",
    "#print(data_names)\n",
    "\n",
    "for i, n in enumerate(range(len(data_names_a))):\n",
    "    if i <= int(len(data_names_a)*0.75):\n",
    "        shutil.copy(data_names_a[n], 'data/train_a/class_att')\n",
    "    else:\n",
    "        shutil.copy(data_names_a[n], 'data/test_a/class_att')\n",
    "for i, n in enumerate(range(len(data_names_c))):\n",
    "    if i <= int(len(data_names_c)*0.75):\n",
    "        shutil.copy(data_names_c[n], 'data/train_c/class_att')\n",
    "    else:\n",
    "        shutil.copy(data_names_c[n], 'data/test_c/class_att')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99737434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_names_a = list(glob.glob('data/Aldanella_sibirica_sp_nov/*Plate_?*_?*a.tif'))\n",
    "data_names_c = list(glob.glob('data/Aldanella_sibirica_sp_nov/*Plate_?*_?*c.tif'))\n",
    "f_1 = open('data/Aldanella_sibirica_sp_nov/different_angle.txt', 'rt')\n",
    "f_2 = open('data/Aldanella_sibirica_sp_nov/miss_view.txt', 'rt')\n",
    "diff_angle = f_1.readlines()\n",
    "miss_view = f_2.readlines()\n",
    "for i, pic in enumerate(diff_angle):\n",
    "    diff_angle[i] = f'data/Aldanella_sibirica_sp_nov\\\\{pic.rstrip()}.tif'#обрезаем символы на конце строки '\\n'\n",
    "for i, pic in enumerate(miss_view):\n",
    "    miss_view[i] = f'data/Aldanella_sibirica_sp_nov\\\\{pic.rstrip()}.tif'\n",
    "\n",
    "for pic in diff_angle:\n",
    "    if pic in data_names_a:\n",
    "        data_names_a.remove(pic)\n",
    "        if pic[:-5]+'c.tif' in data_names_c:\n",
    "            data_names_c.remove(pic[:-5]+'c.tif')\n",
    "for pic in diff_angle:\n",
    "    if pic in data_names_c:\n",
    "        data_names_c.remove(pic)\n",
    "\n",
    "for pic in miss_view:\n",
    "    if (pic[-5:-4] == 'c')==True and (pic[:-5]+'a.tif' in diff_angle)==False and (pic[:-5]+'a.tif' in miss_view)==False:\n",
    "        data_names_a.remove(pic[:-5]+'a.tif')\n",
    "    if pic[-5:-4] == 'a' and (pic[:-5]+'c.tif' in diff_angle)==False and (pic[:-5]+'c.tif' in miss_view)==False:\n",
    "        data_names_c.remove(pic[:-5]+'c.tif')\n",
    "\n",
    "#print(len(data_names_a))\n",
    "#print(data_names_a)\n",
    "#print(len(data_names_c))\n",
    "#print(data_names_c)\n",
    "\n",
    "f_1.close()\n",
    "f_2.close()\n",
    "#print(data_names)\n",
    "\n",
    "for i, n in enumerate(range(len(data_names_a))):\n",
    "    if i <= int(len(data_names_a)*0.75):\n",
    "        shutil.copy(data_names_a[n], 'data/train_a/class_sib')\n",
    "    else:\n",
    "        shutil.copy(data_names_a[n], 'data/test_a/class_sib')\n",
    "for i, n in enumerate(range(len(data_names_c))):\n",
    "    if i <= int(len(data_names_c)*0.75):\n",
    "        shutil.copy(data_names_c[n], 'data/train_c/class_sib')\n",
    "    else:\n",
    "        shutil.copy(data_names_c[n], 'data/test_c/class_sib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60273f",
   "metadata": {},
   "source": [
    "### 1.3 Создание тензеров из изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c477f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255) # масштабируем именно значения каждого пикселя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d796ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 images belonging to 2 classes.\n",
      "Found 59 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Пропускаем через свёртучнуя чать сети изображения (как \"train\", так и \"test\"), чтобы выделить массивы наиболее важных признаков\n",
    "\n",
    "train_generator_a = datagen.flow_from_directory('data/train_a/',\n",
    "                                        target_size=(150, 150),\n",
    "                                        batch_size=10, #количество изображений, пропускаемых через сеть на каждой итерации\n",
    "                                        color_mode='rgb',\n",
    "                                        shuffle=False)\n",
    "train_generator_c = datagen.flow_from_directory('data/train_c/',\n",
    "                                        target_size=(150, 150),\n",
    "                                        batch_size=10, #количество изображений, пропускаемых через сеть на каждой итерации\n",
    "                                        color_mode='rgb',\n",
    "                                        shuffle=False)\n",
    "\n",
    "#Трансофрмацию валидационных данных не нужно делать\n",
    "test_generator_a = datagen.flow_from_directory('data/test_a/',\n",
    "                                              target_size=(150, 150),\n",
    "                                              batch_size=10, #количество изображений, пропускаемых через сеть на каждой итерации,\n",
    "                                              color_mode='rgb',\n",
    "                                              shuffle=False)\n",
    "test_generator_c = datagen.flow_from_directory('data/test_c/',\n",
    "                                              target_size=(150, 150),\n",
    "                                              batch_size=10, #количество изображений, пропускаемых через сеть на каждой итерации,\n",
    "                                              color_mode='rgb',\n",
    "                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c5f5d",
   "metadata": {},
   "source": [
    "## 2. Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bcb316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_model_a = InceptionV3(include_top=False, weights='imagenet', pooling='avg', input_shape=((150, 150, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5910e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_model_c = ResNet50(include_top=False, weights='imagenet', pooling='avg', input_shape=((150, 150, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8488755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 6s 76ms/step\n",
      "6/6 [==============================] - 1s 72ms/step\n",
      "2/2 [==============================] - 0s 149ms/step\n",
      "2/2 [==============================] - 0s 113ms/step\n"
     ]
    }
   ],
   "source": [
    "features_train_a = inc_model_a.predict(train_generator_a)\n",
    "np.save(open('data/binary/train_a_binary/bn_features_exp2_train_a.npy', 'wb'), features_train_a)\n",
    "\n",
    "features_train_c = inc_model_c.predict(train_generator_c)\n",
    "np.save(open('data/binary/train_c_binary/bn_features_exp2_train_c.npy', 'wb'), features_train_c)\n",
    "\n",
    "features_test_a = inc_model_a.predict(test_generator_a)\n",
    "np.save(open('data/binary/test_a_binary/bn_features_exp2_test_a.npy', 'wb'), features_test_a)\n",
    "\n",
    "features_test_c = inc_model_c.predict(test_generator_c)\n",
    "np.save(open('data/binary/test_c_binary/bn_features_exp2_test_c.npy', 'wb'), features_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf90cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_a = np.load(open('data/binary/train_a_binary/bn_features_exp2_train_a.npy', 'rb'))\n",
    "train_labels_a = np.array([0] * 16 + [1] * 43)\n",
    "\n",
    "train_data_c = np.load(open('data/binary/train_c_binary/bn_features_exp2_train_c.npy', 'rb'))\n",
    "train_labels_c = np.array([0] * 16 + [1] * 43) \n",
    "\n",
    "test_data_a = np.load(open('data/binary/test_a_binary/bn_features_exp2_test_a.npy', 'rb'))\n",
    "test_labels_a = np.array([0] * 5 + [1] * 13)\n",
    "\n",
    "test_data_c = np.load(open('data/binary/test_c_binary/bn_features_exp2_test_c.npy', 'rb'))\n",
    "test_labels_c = np.array([0] * 5 + [1] * 13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e68816",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = Sequential()\n",
    "fc_model.add(Flatten(input_shape=train_data_a.shape[1:])) #Явно не создаём слой ввода (input)\n",
    "                                                        #'Flatten' cжимает тензор на входе до вектора заданной формы\n",
    "fc_model.add(Dense(128, activation='relu', name='dense_one')) #можно попробовать функцию активации 'selu'\n",
    "fc_model.add(Dropout(0.5, name='dropout_one')) #выбрасываем сигналы от половины нейронов\n",
    "fc_model.add(Dense(128, activation='relu', name='dense_two'))\n",
    "fc_model.add(Dropout(0.5, name='dropout_two'))\n",
    "fc_model.add(Dense(128, activation='relu', name='dense_three'))\n",
    "fc_model.add(Dropout(0.5, name='dropout_three'))\n",
    "fc_model.add(Dense(1, activation='sigmoid', name='output')) #использовать 'softmax' для многоклассовой классификации\n",
    "#количество нейронов в выходном слое равно количеству классов (записываем максимальный номер класса)\n",
    "\n",
    "fc_model.compile(optimizer='adam', #поиск минимума (может быть 'adam', 'sgd', 'rmsprop')\n",
    "              loss='binary_crossentropy', # 'categorical_crossentropy'\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ff4e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 39ms/step - loss: 1.5882 - accuracy: 0.4746 - val_loss: 0.9670 - val_accuracy: 0.7222\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5829 - accuracy: 0.5763 - val_loss: 0.7076 - val_accuracy: 0.7222\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7065 - accuracy: 0.6102 - val_loss: 0.8299 - val_accuracy: 0.7222\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.6846 - accuracy: 0.5763 - val_loss: 0.7681 - val_accuracy: 0.7222\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3465 - accuracy: 0.6441 - val_loss: 0.5767 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7318 - accuracy: 0.6441 - val_loss: 0.5362 - val_accuracy: 0.7222\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0762 - accuracy: 0.5932 - val_loss: 0.5377 - val_accuracy: 0.7222\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8036 - accuracy: 0.7288 - val_loss: 0.5920 - val_accuracy: 0.7222\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6141 - accuracy: 0.7119 - val_loss: 0.5557 - val_accuracy: 0.7222\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5381 - accuracy: 0.6949 - val_loss: 0.5048 - val_accuracy: 0.7778\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4878 - accuracy: 0.7458 - val_loss: 0.4890 - val_accuracy: 0.7222\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5086 - accuracy: 0.7288 - val_loss: 0.5155 - val_accuracy: 0.7222\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4440 - accuracy: 0.7627 - val_loss: 0.5598 - val_accuracy: 0.7222\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5479 - accuracy: 0.7288 - val_loss: 0.5336 - val_accuracy: 0.7778\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4044 - accuracy: 0.8136 - val_loss: 0.5436 - val_accuracy: 0.7778\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3844 - accuracy: 0.8305 - val_loss: 0.5859 - val_accuracy: 0.7778\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4123 - accuracy: 0.7627 - val_loss: 0.5728 - val_accuracy: 0.7778\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4184 - accuracy: 0.7966 - val_loss: 0.5777 - val_accuracy: 0.7778\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3974 - accuracy: 0.8305 - val_loss: 0.5960 - val_accuracy: 0.7778\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4159 - accuracy: 0.7627 - val_loss: 0.6299 - val_accuracy: 0.7778\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3685 - accuracy: 0.7797 - val_loss: 0.7161 - val_accuracy: 0.7222\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3472 - accuracy: 0.7627 - val_loss: 0.7319 - val_accuracy: 0.7222\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4174 - accuracy: 0.7458 - val_loss: 0.6423 - val_accuracy: 0.7222\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4291 - accuracy: 0.7797 - val_loss: 0.7321 - val_accuracy: 0.7778\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3776 - accuracy: 0.8136 - val_loss: 0.7425 - val_accuracy: 0.7778\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3785 - accuracy: 0.7966 - val_loss: 0.7502 - val_accuracy: 0.8333\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3938 - accuracy: 0.7797 - val_loss: 0.7713 - val_accuracy: 0.7778\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3595 - accuracy: 0.7797 - val_loss: 0.7870 - val_accuracy: 0.7222\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3479 - accuracy: 0.8475 - val_loss: 0.9411 - val_accuracy: 0.7222\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3405 - accuracy: 0.7966 - val_loss: 0.9891 - val_accuracy: 0.7222\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3315 - accuracy: 0.8136 - val_loss: 1.0502 - val_accuracy: 0.7222\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3357 - accuracy: 0.8305 - val_loss: 1.0136 - val_accuracy: 0.7222\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3713 - accuracy: 0.7797 - val_loss: 0.9990 - val_accuracy: 0.7222\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3041 - accuracy: 0.8475 - val_loss: 1.0446 - val_accuracy: 0.7222\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2575 - accuracy: 0.8983 - val_loss: 1.3479 - val_accuracy: 0.7222\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2776 - accuracy: 0.8475 - val_loss: 1.0607 - val_accuracy: 0.7222\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3150 - accuracy: 0.8475 - val_loss: 1.0960 - val_accuracy: 0.7222\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2657 - accuracy: 0.8475 - val_loss: 1.2150 - val_accuracy: 0.7222\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2727 - accuracy: 0.8475 - val_loss: 1.3105 - val_accuracy: 0.7778\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2877 - accuracy: 0.8814 - val_loss: 1.2968 - val_accuracy: 0.7778\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1759 - accuracy: 0.9322 - val_loss: 1.4611 - val_accuracy: 0.7222\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2530 - accuracy: 0.8644 - val_loss: 1.3252 - val_accuracy: 0.7222\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2756 - accuracy: 0.8136 - val_loss: 1.1836 - val_accuracy: 0.7222\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2116 - accuracy: 0.8644 - val_loss: 1.2950 - val_accuracy: 0.7222\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3200 - accuracy: 0.8305 - val_loss: 1.5160 - val_accuracy: 0.7778\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2085 - accuracy: 0.8983 - val_loss: 1.4594 - val_accuracy: 0.7222\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1864 - accuracy: 0.8983 - val_loss: 1.5230 - val_accuracy: 0.7222\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1891 - accuracy: 0.9322 - val_loss: 1.6894 - val_accuracy: 0.7222\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1775 - accuracy: 0.9322 - val_loss: 1.8829 - val_accuracy: 0.7222\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1477 - accuracy: 0.9322 - val_loss: 1.9469 - val_accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "fc_model.fit(train_data_a, train_labels_a,\n",
    "            epochs=50, batch_size=10,\n",
    "            validation_data=(test_data_a, test_labels_a))\n",
    "\n",
    "fc_model.save_weights('data/model_weights/exp2_a.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39db167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = Sequential()\n",
    "fc_model.add(Flatten(input_shape=train_data_a.shape[1:])) #Явно не создаём слой ввода (input)\n",
    "                                                        #'Flatten' cжимает тензор на входе до вектора заданной формы\n",
    "fc_model.add(Dense(128, activation='relu', name='dense_one')) #можно попробовать функцию активации 'selu'\n",
    "fc_model.add(Dropout(0.5, name='dropout_one')) #выбрасываем сигналы от половины нейронов\n",
    "fc_model.add(Dense(128, activation='relu', name='dense_two'))\n",
    "fc_model.add(Dropout(0.5, name='dropout_two'))\n",
    "fc_model.add(Dense(128, activation='relu', name='dense_three'))\n",
    "fc_model.add(Dropout(0.5, name='dropout_three'))\n",
    "fc_model.add(Dense(1, activation='sigmoid', name='output')) #использовать 'softmax' для многоклассовой классификации\n",
    "#количество нейронов в выходном слое равно количеству классов (записываем максимальный номер класса)\n",
    "\n",
    "fc_model.compile(optimizer='adam', #поиск минимума (может быть 'adam', 'sgd', 'rmsprop')\n",
    "              loss='binary_crossentropy', # 'categorical_crossentropy'\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a433197b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 32ms/step - loss: 0.6065 - accuracy: 0.6610 - val_loss: 0.6076 - val_accuracy: 0.7222\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7123 - accuracy: 0.6610 - val_loss: 0.6262 - val_accuracy: 0.7222\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6492 - accuracy: 0.7119 - val_loss: 0.5969 - val_accuracy: 0.7222\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6772 - accuracy: 0.6441 - val_loss: 0.5998 - val_accuracy: 0.7222\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6026 - accuracy: 0.6949 - val_loss: 0.6026 - val_accuracy: 0.7222\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6190 - accuracy: 0.7288 - val_loss: 0.5933 - val_accuracy: 0.7222\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7196 - accuracy: 0.6441 - val_loss: 0.5933 - val_accuracy: 0.7222\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7377 - accuracy: 0.6102 - val_loss: 0.5924 - val_accuracy: 0.7222\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6308 - accuracy: 0.7119 - val_loss: 0.5948 - val_accuracy: 0.7222\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6403 - accuracy: 0.6780 - val_loss: 0.5970 - val_accuracy: 0.7222\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6098 - accuracy: 0.7288 - val_loss: 0.6021 - val_accuracy: 0.7222\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5772 - accuracy: 0.7119 - val_loss: 0.5940 - val_accuracy: 0.7222\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6196 - accuracy: 0.7119 - val_loss: 0.5955 - val_accuracy: 0.7222\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6046 - accuracy: 0.7119 - val_loss: 0.5976 - val_accuracy: 0.7222\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6094 - accuracy: 0.7288 - val_loss: 0.6008 - val_accuracy: 0.7222\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6017 - accuracy: 0.6949 - val_loss: 0.6049 - val_accuracy: 0.7222\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6541 - accuracy: 0.6780 - val_loss: 0.6040 - val_accuracy: 0.7222\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6448 - accuracy: 0.7119 - val_loss: 0.6008 - val_accuracy: 0.7222\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5928 - accuracy: 0.7288 - val_loss: 0.6012 - val_accuracy: 0.7222\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5598 - accuracy: 0.7458 - val_loss: 0.5919 - val_accuracy: 0.7222\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6050 - accuracy: 0.6949 - val_loss: 0.5905 - val_accuracy: 0.7222\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5982 - accuracy: 0.7458 - val_loss: 0.5905 - val_accuracy: 0.7222\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6632 - accuracy: 0.7288 - val_loss: 0.5915 - val_accuracy: 0.7222\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6201 - accuracy: 0.7288 - val_loss: 0.5922 - val_accuracy: 0.7222\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5741 - accuracy: 0.7119 - val_loss: 0.5961 - val_accuracy: 0.7222\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6120 - accuracy: 0.7119 - val_loss: 0.5936 - val_accuracy: 0.7222\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6272 - accuracy: 0.7288 - val_loss: 0.6046 - val_accuracy: 0.7222\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5978 - accuracy: 0.7119 - val_loss: 0.6048 - val_accuracy: 0.7222\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6229 - accuracy: 0.7119 - val_loss: 0.6043 - val_accuracy: 0.7222\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6712 - accuracy: 0.7288 - val_loss: 0.6073 - val_accuracy: 0.7222\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5996 - accuracy: 0.7288 - val_loss: 0.6068 - val_accuracy: 0.7222\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6321 - accuracy: 0.7288 - val_loss: 0.6043 - val_accuracy: 0.7222\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5828 - accuracy: 0.7288 - val_loss: 0.5968 - val_accuracy: 0.7222\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6061 - accuracy: 0.7458 - val_loss: 0.5957 - val_accuracy: 0.7222\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5732 - accuracy: 0.7288 - val_loss: 0.5935 - val_accuracy: 0.7222\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5646 - accuracy: 0.7288 - val_loss: 0.5930 - val_accuracy: 0.7222\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5776 - accuracy: 0.7288 - val_loss: 0.5900 - val_accuracy: 0.7222\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5470 - accuracy: 0.7288 - val_loss: 0.5896 - val_accuracy: 0.7222\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6148 - accuracy: 0.7288 - val_loss: 0.5896 - val_accuracy: 0.7222\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6510 - accuracy: 0.7288 - val_loss: 0.5922 - val_accuracy: 0.7222\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5673 - accuracy: 0.7288 - val_loss: 0.5968 - val_accuracy: 0.7222\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6079 - accuracy: 0.7119 - val_loss: 0.5958 - val_accuracy: 0.7222\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5870 - accuracy: 0.7288 - val_loss: 0.5958 - val_accuracy: 0.7222\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6488 - accuracy: 0.7288 - val_loss: 0.5955 - val_accuracy: 0.7222\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5543 - accuracy: 0.7288 - val_loss: 0.5987 - val_accuracy: 0.7222\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5908 - accuracy: 0.7288 - val_loss: 0.5979 - val_accuracy: 0.7222\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5432 - accuracy: 0.7288 - val_loss: 0.5950 - val_accuracy: 0.7222\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6308 - accuracy: 0.7288 - val_loss: 0.5926 - val_accuracy: 0.7222\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6181 - accuracy: 0.7288 - val_loss: 0.5926 - val_accuracy: 0.7222\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5855 - accuracy: 0.7288 - val_loss: 0.5921 - val_accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "fc_model.fit(train_data_c, train_labels_c,\n",
    "            epochs=50, batch_size=10,\n",
    "            validation_data=(test_data_c, test_labels_c))\n",
    "\n",
    "fc_model.save_weights('data/model_weights/exp2_c.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d4ee66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 images belonging to 2 classes.\n",
      "Found 59 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\npred_generator=test_datagen.flow_from_directory('data/img_val/',\\n                                                     target_size=(150,150),\\n                                                     batch_size=100,\\n                                                     class_mode='binary')\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator_a = train_datagen.flow_from_directory('data/train_a/',\n",
    "                                        target_size=(150, 150),\n",
    "                                        batch_size=100,\n",
    "                                        color_mode='rgb',\n",
    "                                        class_mode='binary',\n",
    "                                        shuffle=True)\n",
    "train_generator_c = train_datagen.flow_from_directory('data/train_c/',\n",
    "                                        target_size=(150, 150),\n",
    "                                        batch_size=100,\n",
    "                                        color_mode='rgb',\n",
    "                                        class_mode='binary',\n",
    "                                        shuffle=True)\n",
    "\n",
    "validation_generator_a = test_datagen.flow_from_directory('data/test_a/',\n",
    "                                              target_size=(150, 150),\n",
    "                                              batch_size=100,\n",
    "                                              color_mode='rgb',\n",
    "                                              class_mode='binary',\n",
    "                                              shuffle=True)\n",
    "validation_generator_c = test_datagen.flow_from_directory('data/test_c/',\n",
    "                                              target_size=(150, 150),\n",
    "                                              batch_size=100,\n",
    "                                              color_mode='rgb',\n",
    "                                              class_mode='binary',\n",
    "                                              shuffle=True)\n",
    "\n",
    "'''\n",
    "pred_generator=test_datagen.flow_from_directory('data/img_val/',\n",
    "                                                     target_size=(150,150),\n",
    "                                                     batch_size=100,\n",
    "                                                     class_mode='binary')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b215ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, y_train_a = train_generator_a.next()\n",
    "X_train_c, y_train_c = train_generator_c.next()\n",
    "\n",
    "X_validation_a, y_validation_a = validation_generator_a.next()\n",
    "X_validation_c, y_validation_c = validation_generator_c.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2a417a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10c81d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(inc_model_a.output)\n",
    "x = Dense(128, activation='relu', name='dense_a_one')(x)\n",
    "x = Dropout(0.5, name='dropout_a_one')(x)\n",
    "x = Dense(128, activation='relu', name='dense_a_two')(x)\n",
    "x = Dropout(0.5, name='dropout_a_two')(x)\n",
    "x = Dense(128, activation='relu', name='dense_a_three')(x)\n",
    "x = Dropout(0.5, name='dropout_a_three')(x)\n",
    "#top_model=Dense(1, activation='sigmoid', name='output')(x)\n",
    "model_a = Model(inputs=inc_model_a.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd7af5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(inc_model_c.output)\n",
    "x = Dense(128, activation='relu', name='dense_c_one')(x)\n",
    "x = Dropout(0.5, name='dropout_c_one')(x)\n",
    "x = Dense(128, activation='relu', name='dense_c_two')(x)\n",
    "x = Dropout(0.5, name='dropout_c_two')(x)\n",
    "x = Dense(128, activation='relu', name='dense_c_three')(x)\n",
    "x = Dropout(0.5, name='dropout_c_three')(x)\n",
    "#top_model=Dense(1, activation='sigmoid', name='output')(x)\n",
    "model_c = Model(inputs=inc_model_c.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e3a52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filename='data/model_weights/exp2_a.hdf5'\n",
    "model_a.load_weights(weights_filename, by_name=True)\n",
    "\n",
    "weights_filename='data/model_weights/exp2_c.hdf5'\n",
    "model_c.load_weights(weights_filename, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "910392d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedInput = Concatenate()([model_a.output, model_c.output])\n",
    "x = Dense(256, activation='relu')(combinedInput)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "top = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=[model_a.input, model_c.input], outputs=top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35f3bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "974ba1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(learning_rate=1e-4, momentum=0.9),\n",
    "                #optimizer='adam',\n",
    "              #optimizer=Adam(learning_rate=1e-4, decay=1e-4 / 200),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5b3d5ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "11305f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 10s 427ms/step - loss: 0.2610 - accuracy: 0.7458 - val_loss: 1.1433 - val_accuracy: 0.7222\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 0.2016 - accuracy: 0.7627 - val_loss: 1.1402 - val_accuracy: 0.7222\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 0.2123 - accuracy: 0.7458 - val_loss: 1.1436 - val_accuracy: 0.7222\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 0.2220 - accuracy: 0.7288 - val_loss: 1.1525 - val_accuracy: 0.7222\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 0.2220 - accuracy: 0.7458 - val_loss: 1.1592 - val_accuracy: 0.7222\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 0.2229 - accuracy: 0.7797 - val_loss: 1.1683 - val_accuracy: 0.7222\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 0.2473 - accuracy: 0.7458 - val_loss: 1.1805 - val_accuracy: 0.7222\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 0.2161 - accuracy: 0.7288 - val_loss: 1.1934 - val_accuracy: 0.7222\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.2122 - accuracy: 0.7797 - val_loss: 1.1955 - val_accuracy: 0.7222\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 0.1982 - accuracy: 0.8305 - val_loss: 1.1984 - val_accuracy: 0.7222\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.2024 - accuracy: 0.7966 - val_loss: 1.2037 - val_accuracy: 0.7222\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 1s 132ms/step - loss: 0.2119 - accuracy: 0.7288 - val_loss: 1.2141 - val_accuracy: 0.7222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b45950d8b0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_a, X_train_c], train_labels_a,\n",
    "            validation_data=([X_validation_a, X_validation_c], y_validation_a),\n",
    "            epochs=200, batch_size=10,\n",
    "            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a42729b2",
   "metadata": {},
   "source": [
    "model.fit([train_generator_a, train_generator_c], y_train_a,\n",
    "            validation_data=([validation_generator_a, validation_generator_c], test_labels_a),\n",
    "            epochs=200, batch_size=10,\n",
    "            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "82e361d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 217ms/step - loss: 1.2141 - accuracy: 0.7222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.2141032218933105, 'accuracy': 0.7222222089767456}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate([X_validation_a, X_validation_c], y_validation_a)\n",
    "dict(zip(fc_model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd07d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
